{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bedbb50-c663-437a-89e9-37480ac97421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67225620-aa09-4244-9fb4-fcb6ad64ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4066f9f7-154b-40a5-a829-02e625655133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cb12c1c-e566-4e25-a99b-6af358b97397",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Churn_Yes\", axis=1)  # ou \"Churn\" si pas encore encod√©\n",
    "y = df[\"Churn_Yes\"]               # cible binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3afe0709-7c12-46ff-b685-9db856bbaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4687d3f-a843-4810-bbda-b75c3dd39a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f27da48-b19d-4106-945d-9bf7fce967ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3230c312-fe81-48c7-91fd-c999437552c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7615330021291696\n",
      "Confusion Matrix:\n",
      " [[1019   17]\n",
      " [ 319   54]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.98      0.86      1036\n",
      "        True       0.76      0.14      0.24       373\n",
      "\n",
      "    accuracy                           0.76      1409\n",
      "   macro avg       0.76      0.56      0.55      1409\n",
      "weighted avg       0.76      0.76      0.70      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe7d6c90-6118-40d4-9eb2-352e51e12d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1bde5e5-4695-4b56-a472-f4ee321bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2b3c4d8-210e-4a3b-9ff9-daececf22179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# REFAIRE l'encodage si besoin (tu peux garder df comme nom)\n",
    "X = df.drop(\"Churn_Yes\", axis=1)\n",
    "y = df[\"Churn_Yes\"]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c72d65e-050e-4392-95fe-465b4fa05900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.8034066713981547\n",
      "Confusion Matrix:\n",
      " [[963  73]\n",
      " [204 169]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.93      0.87      1036\n",
      "        True       0.70      0.45      0.55       373\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.76      0.69      0.71      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Accuracy: 0.78708303761533\n",
      "Confusion Matrix:\n",
      " [[915 121]\n",
      " [179 194]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.88      0.86      1036\n",
      "        True       0.62      0.52      0.56       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.73      0.70      0.71      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n",
      "\n",
      "K-Nearest Neighbors\n",
      "Accuracy: 0.7338537970191625\n",
      "Confusion Matrix:\n",
      " [[1032    4]\n",
      " [ 371    2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      1.00      0.85      1036\n",
      "        True       0.33      0.01      0.01       373\n",
      "\n",
      "    accuracy                           0.73      1409\n",
      "   macro avg       0.53      0.50      0.43      1409\n",
      "weighted avg       0.63      0.73      0.63      1409\n",
      "\n",
      "\n",
      "Support Vector Machine\n",
      "Accuracy: 0.28601845280340665\n",
      "Confusion Matrix:\n",
      " [[ 54 982]\n",
      " [ 24 349]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.05      0.10      1036\n",
      "        True       0.26      0.94      0.41       373\n",
      "\n",
      "    accuracy                           0.29      1409\n",
      "   macro avg       0.48      0.49      0.25      1409\n",
      "weighted avg       0.58      0.29      0.18      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "evaluate_model(RandomForestClassifier(random_state=42), X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nXGBoost\")\n",
    "evaluate_model(XGBClassifier(eval_metric='logloss'), X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors\")\n",
    "evaluate_model(KNeighborsClassifier(), X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nSupport Vector Machine\")\n",
    "evaluate_model(SVC(), X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baa1d8d5-d0a1-4d2a-8eaf-9ae0629ebfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest accuracy: 0.7913413768630234\n",
      "------------------------------\n",
      "Training XGBoost...\n",
      "XGBoost accuracy: 0.7743080198722498\n",
      "------------------------------\n",
      "Training KNN...\n",
      "KNN accuracy: 0.7345635202271115\n",
      "------------------------------\n",
      "Training SVM...\n",
      "SVM accuracy: 0.7409510290986515\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, train_size=0.4, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_small, y_train_small)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"{name} accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4256b74f-1866-4259-8aae-5f9ea3a354f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (avec class_weight='balanced')\n",
      "Accuracy: 0.8097941802696949\n",
      "Confusion Matrix:\n",
      " [[946  90]\n",
      " [178 195]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.91      0.88      1036\n",
      "        True       0.68      0.52      0.59       373\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.76      0.72      0.73      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n",
      "\n",
      "XGBoost (avec scale_pos_weight)\n",
      "Accuracy: 0.7650816181689141\n",
      "Confusion Matrix:\n",
      " [[807 229]\n",
      " [102 271]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.78      0.83      1036\n",
      "        True       0.54      0.73      0.62       373\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.75      0.73      1409\n",
      "weighted avg       0.80      0.77      0.77      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"Random Forest (avec class_weight='balanced')\")\n",
    "rf_balanced = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "evaluate_model(rf_balanced, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nXGBoost (avec scale_pos_weight)\")\n",
    "# Calculer scale_pos_weight = nbr n√©gatifs / nbr positifs pour XGBoost\n",
    "scale_pos_weight = y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]\n",
    "xgb_balanced = XGBClassifier(eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
    "evaluate_model(xgb_balanced, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "825b73f5-4795-4114-9390-3086fda326fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs param√®tres: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.8062455642299503\n",
      "Confusion Matrix:\n",
      " [[890 146]\n",
      " [127 246]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.86      0.87      1036\n",
      "        True       0.63      0.66      0.64       373\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.76      0.76      1409\n",
      "weighted avg       0.81      0.81      0.81      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs param√®tres:\", grid_search.best_params_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "evaluate_model(best_rf, X_train, X_test, y_train, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
